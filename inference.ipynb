{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f7ac6c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-11T04:38:38.988827Z",
     "iopub.status.busy": "2025-07-11T04:38:38.988451Z",
     "iopub.status.idle": "2025-07-11T04:38:47.816360Z",
     "shell.execute_reply": "2025-07-11T04:38:47.815680Z"
    },
    "papermill": {
     "duration": 8.835349,
     "end_time": "2025-07-11T04:38:47.817894",
     "exception": false,
     "start_time": "2025-07-11T04:38:38.982545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import random\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c0087e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T04:38:47.826202Z",
     "iopub.status.busy": "2025-07-11T04:38:47.825816Z",
     "iopub.status.idle": "2025-07-11T04:38:47.838236Z",
     "shell.execute_reply": "2025-07-11T04:38:47.837621Z"
    },
    "papermill": {
     "duration": 0.017842,
     "end_time": "2025-07-11T04:38:47.839572",
     "exception": false,
     "start_time": "2025-07-11T04:38:47.821730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_gravity_from_acc(acc_data, rot_data):\n",
    "    \"\"\"Remove gravity component from accelerometer data\"\"\"\n",
    "    if isinstance(acc_data, pd.DataFrame):\n",
    "        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n",
    "    else:\n",
    "        acc_values = acc_data\n",
    "\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = acc_values.shape[0]\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    gravity_world = np.array([0, 0, 9.802])\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i, :] = acc_values[i, :]\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "            linear_accel[i, :] = acc_values[i, :]\n",
    "\n",
    "    return linear_accel\n",
    "\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/200):\n",
    "    \"\"\"Calculate angular velocity from quaternion derivatives\"\"\"\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_vel = np.zeros((num_samples, 3))\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q_t = quat_values[i]\n",
    "        q_t_plus_dt = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n",
    "           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    return angular_vel\n",
    "\n",
    "def calculate_angular_distance(rot_data):\n",
    "    \"\"\"Calculate angular distance between successive quaternions\"\"\"\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_dist = np.zeros(num_samples)\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q1 = quat_values[i]\n",
    "        q2 = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n",
    "           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n",
    "            angular_dist[i] = 0\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            angle = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "            angular_dist[i] = angle\n",
    "        except ValueError:\n",
    "            angular_dist[i] = 0\n",
    "\n",
    "    return angular_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc7ba37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T04:38:47.847315Z",
     "iopub.status.busy": "2025-07-11T04:38:47.847059Z",
     "iopub.status.idle": "2025-07-11T04:38:47.859905Z",
     "shell.execute_reply": "2025-07-11T04:38:47.859311Z"
    },
    "papermill": {
     "duration": 0.018176,
     "end_time": "2025-07-11T04:38:47.861077",
     "exception": false,
     "start_time": "2025-07-11T04:38:47.842901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IMUModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # MLP for initial feature transformation (applied at each time step)\n",
    "        self.feature_mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "            \n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "            \n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Temporal feature extraction with 1D CNNs\n",
    "        self.temporal_conv = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Conv1d(256, 256, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        # Multi-scale temporal feature extractor (original kernel sizes)\n",
    "        self.multi_scale = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(256, 64, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(256, 64, kernel_size=5, padding=2),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(256, 64, kernel_size=7, padding=3),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(256, 64, kernel_size=11, padding=5),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        # Temporal pyramid pooling\n",
    "        self.pyramid_pool = nn.ModuleList([\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.AdaptiveAvgPool1d(2),\n",
    "            nn.AdaptiveAvgPool1d(4)\n",
    "        ])\n",
    "\n",
    "        # Final classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512*7, 256),  # 7 = 1+2+4 from pyramid pooling\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x shape: (B, T, C) where B=batch, T=time, C=channels\n",
    "        batch_size, seq_len, feat_dim = x.shape\n",
    "        \n",
    "        # Apply MLP to each time step independently\n",
    "        # Reshape to (B*T, C) for batch processing through MLP\n",
    "        x_reshaped = x.view(-1, feat_dim)\n",
    "        x_transformed = self.feature_mlp(x_reshaped)\n",
    "        \n",
    "        # Reshape back to (B, T, hidden_dim) and transpose to (B, hidden_dim, T) for Conv1d\n",
    "        x = x_transformed.view(batch_size, seq_len, -1).transpose(1, 2)\n",
    "\n",
    "        # Temporal feature extraction\n",
    "        x = self.temporal_conv(x)\n",
    "\n",
    "        # Multi-scale temporal feature extraction\n",
    "        scale_features = []\n",
    "        for conv in self.multi_scale:\n",
    "            scale_features.append(conv(x))\n",
    "        x = torch.cat(scale_features, dim=1)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Masking for variable length sequences\n",
    "        max_time = x.size(2)\n",
    "        mask = torch.arange(max_time, device=x.device)[None, :] < lengths[:, None]\n",
    "        mask = mask.unsqueeze(1).float()\n",
    "        x = x * mask\n",
    "\n",
    "        # Temporal pyramid pooling\n",
    "        pyramid_features = []\n",
    "        for pool in self.pyramid_pool:\n",
    "            pooled = pool(x)  # (B, C, pool_size)\n",
    "            pooled = pooled.view(pooled.size(0), -1)  # Flatten\n",
    "            pyramid_features.append(pooled)\n",
    "\n",
    "        # Combine features\n",
    "        features = torch.cat(pyramid_features, dim=1)\n",
    "\n",
    "        # Classification\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ac47a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T04:38:47.868508Z",
     "iopub.status.busy": "2025-07-11T04:38:47.868225Z",
     "iopub.status.idle": "2025-07-11T04:38:47.873956Z",
     "shell.execute_reply": "2025-07-11T04:38:47.873380Z"
    },
    "papermill": {
     "duration": 0.010787,
     "end_time": "2025-07-11T04:38:47.875150",
     "exception": false,
     "start_time": "2025-07-11T04:38:47.864363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a06a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T04:38:47.882416Z",
     "iopub.status.busy": "2025-07-11T04:38:47.882145Z",
     "iopub.status.idle": "2025-07-11T04:38:49.700377Z",
     "shell.execute_reply": "2025-07-11T04:38:49.699441Z"
    },
    "papermill": {
     "duration": 1.823382,
     "end_time": "2025-07-11T04:38:49.701795",
     "exception": false,
     "start_time": "2025-07-11T04:38:47.878413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 10 models\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model ensemble\n",
    "model_ensemble = []\n",
    "for i in range(0, 10):\n",
    "    # Create model instance\n",
    "    model = IMUModel(28, 18).to(device)\n",
    "    \n",
    "    # Load weights\n",
    "\n",
    "    model_path = f\"/kaggle/input/trained-model/bst_model_fold{i}.pth\"\n",
    "\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    model_ensemble.append(model)\n",
    "\n",
    "print(f\"✅ Successfully loaded {len(model_ensemble)} models\")\n",
    "\n",
    "# Example inference function using ensemble\n",
    "def ensemble_predict(x):\n",
    "    \"\"\"\n",
    "    Predict using model ensemble with averaging\n",
    "    \n",
    "    Args:\n",
    "        x: Input tensor (batch_size, seq_len, features)\n",
    "    \n",
    "    Returns:\n",
    "        logits: Averaged logits from all models\n",
    "        probs: Class probabilities\n",
    "        preds: Class predictions\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Get predictions from all models\n",
    "        all_logits = []\n",
    "        for model in model_ensemble:\n",
    "            logits = model(x)\n",
    "            all_logits.append(logits)\n",
    "        \n",
    "        # Average logits across models\n",
    "        avg_logits = torch.mean(torch.stack(all_logits), dim=0)\n",
    "        probs = torch.softmax(avg_logits, dim=-1)\n",
    "        preds = torch.argmax(probs, dim=-1)\n",
    "        \n",
    "    return avg_logits, probs, preds\n",
    "\n",
    "# Usage example:\n",
    "# x = torch.randn(32, 128, 20).to(device)  # Example input\n",
    "# logits, probs, preds = ensemble_predict(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a803d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T04:38:49.709587Z",
     "iopub.status.busy": "2025-07-11T04:38:49.709301Z",
     "iopub.status.idle": "2025-07-11T04:39:28.294225Z",
     "shell.execute_reply": "2025-07-11T04:39:28.293570Z"
    },
    "papermill": {
     "duration": 38.590406,
     "end_time": "2025-07-11T04:39:28.295800",
     "exception": false,
     "start_time": "2025-07-11T04:38:49.705394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_imu_cols = ['acc_x', 'acc_y', 'acc_z', 'rot_x', 'rot_y', 'rot_z', 'rot_w']\n",
    "\n",
    "imu_cols = initial_imu_cols + [\n",
    "    # Engineered features\n",
    "    'acc_mag', 'rot_angle',\n",
    "    'acc_mag_jerk', 'rot_angle_vel',\n",
    "    'linear_acc_x', 'linear_acc_y', 'linear_acc_z',\n",
    "    'linear_acc_mag', 'linear_acc_mag_jerk',\n",
    "    'angular_vel_x', 'angular_vel_y', 'angular_vel_z',\n",
    "    'angular_distance'\n",
    "]\n",
    "df = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv')\n",
    "gestures = sorted(df['gesture'].unique())\n",
    "idx_to_gesture = {i: g for i, g in enumerate(gestures)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c3a98a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T04:39:28.304032Z",
     "iopub.status.busy": "2025-07-11T04:39:28.303783Z",
     "iopub.status.idle": "2025-07-11T04:39:28.330487Z",
     "shell.execute_reply": "2025-07-11T04:39:28.329726Z"
    },
    "papermill": {
     "duration": 0.032485,
     "end_time": "2025-07-11T04:39:28.331806",
     "exception": false,
     "start_time": "2025-07-11T04:39:28.299321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBlock1D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class FPN1D(nn.Module):\n",
    "    def __init__(self, in_channels=256, out_channels=256):\n",
    "        super().__init__()\n",
    "        self.lateral_conv0 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        self.lateral_conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        self.lateral_conv2 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "        self.smooth_conv0 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.smooth_conv1 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.smooth_conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, c0):\n",
    "        c1 = F.max_pool1d(c0, kernel_size=2, stride=2, ceil_mode=True)\n",
    "        c2 = F.max_pool1d(c1, kernel_size=2, stride=2, ceil_mode=True)\n",
    "\n",
    "        p0 = self.lateral_conv0(c0)\n",
    "        p1 = self.lateral_conv1(c1)\n",
    "        p2 = self.lateral_conv2(c2)\n",
    "\n",
    "        p2_up = F.interpolate(p2, size=p1.size(2), mode='linear', align_corners=True)\n",
    "        p1_combined = p1 + p2_up\n",
    "        p1_smoothed = self.smooth_conv1(p1_combined)\n",
    "\n",
    "        p1_up = F.interpolate(p1_smoothed, size=p0.size(2), mode='linear', align_corners=True)\n",
    "        p0_combined = p0 + p1_up\n",
    "        p0_smoothed = self.smooth_conv0(p0_combined)\n",
    "\n",
    "        return p0_smoothed\n",
    "\n",
    "class SensorBranch(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # 1×1 projection\n",
    "        self.input_proj = nn.Conv1d(input_dim, 256, kernel_size=1)\n",
    "\n",
    "        # Residual blocks\n",
    "        self.res_cnn = nn.Sequential(\n",
    "            ResidualBlock1D(256),\n",
    "            ResidualBlock1D(256),\n",
    "            ResidualBlock1D(256),\n",
    "        )\n",
    "\n",
    "        # Feature Pyramid Network\n",
    "        self.fpn = FPN1D(256, 256)\n",
    "\n",
    "        # GRU layers\n",
    "        self.gru1 = nn.GRU(256, hidden_dim, num_layers=3, batch_first=True, bidirectional=True)\n",
    "        self.gru2 = nn.GRU(hidden_dim*2, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.gru3 = nn.GRU(hidden_dim*2, hidden_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Skip connection\n",
    "        self.skip_proj = nn.Linear(256, hidden_dim*2)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name and 'gru' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name and 'gru' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif isinstance(param, nn.Linear):\n",
    "                nn.init.xavier_uniform_(param)\n",
    "                if param.bias is not None:\n",
    "                    nn.init.zeros_(param.bias)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Input transformation\n",
    "        x = x.transpose(1, 2)  # (B, C, T)\n",
    "        x = self.input_proj(x)\n",
    "        x = self.res_cnn(x)\n",
    "        x = self.fpn(x)\n",
    "        x = x.transpose(1, 2)  # (B, T, C)\n",
    "\n",
    "        # GRU processing\n",
    "        packed1 = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        out1, _ = self.gru1(packed1)\n",
    "        pad1, _ = pad_packed_sequence(out1, batch_first=True)\n",
    "        skip1 = self.skip_proj(x)\n",
    "        prev = pad1 + skip1\n",
    "\n",
    "        packed2 = pack_padded_sequence(prev, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        out2, _ = self.gru2(packed2)\n",
    "        pad2, _ = pad_packed_sequence(out2, batch_first=True)\n",
    "        prev = pad2 + prev\n",
    "\n",
    "        packed3 = pack_padded_sequence(prev, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        out3, _ = self.gru3(packed3)\n",
    "        pad3, _ = pad_packed_sequence(out3, batch_first=True)\n",
    "        prev = pad3 + prev\n",
    "\n",
    "        # Last timestep\n",
    "        idx = (lengths - 1).unsqueeze(1).unsqueeze(2).expand(-1, 1, prev.size(2))\n",
    "        last = prev.gather(1, idx).squeeze(1)\n",
    "\n",
    "        return last\n",
    "\n",
    "class MultiSensorClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 imu_input_dim=20,  # Updated for engineered features\n",
    "                 thm_input_dim=5,\n",
    "                 tof_input_dim=64,\n",
    "                 hidden_dim=256,\n",
    "                 num_heads=8,\n",
    "                 ffn_hidden=256,\n",
    "                 num_classes=18,\n",
    "                 p_branch_mask=0.1,\n",
    "                 p_feat_dropout=0.2):\n",
    "        super().__init__()\n",
    "        # Sensor branches\n",
    "        self.imu_branch = SensorBranch(imu_input_dim, hidden_dim)\n",
    "        self.thm_branch = SensorBranch(thm_input_dim, hidden_dim)\n",
    "        self.tof_branches = nn.ModuleList([\n",
    "            SensorBranch(tof_input_dim, hidden_dim) for _ in range(5)\n",
    "        ])\n",
    "\n",
    "        # Feature fusion\n",
    "        self.pre_norm = nn.LayerNorm(hidden_dim*2)\n",
    "        self.attention_layers = nn.ModuleList([\n",
    "            nn.ModuleDict({\n",
    "                'attention': nn.MultiheadAttention(\n",
    "                    embed_dim=hidden_dim*2,\n",
    "                    num_heads=num_heads,\n",
    "                    batch_first=True\n",
    "                ),\n",
    "                'norm': nn.LayerNorm(hidden_dim*2)\n",
    "            }) for _ in range(3)\n",
    "        ])\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, ffn_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ffn_hidden, hidden_dim*2)\n",
    "        )\n",
    "        self.post_norm = nn.LayerNorm(hidden_dim*2)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(hidden_dim*2, num_classes)\n",
    "        nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "\n",
    "        # Regularization\n",
    "        self.p_branch_mask = p_branch_mask\n",
    "        self.feat_dropout = nn.Dropout(p_feat_dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                imu_seq, imu_len,\n",
    "                thm_seq, thm_len,\n",
    "                tof_inputs, tof_len,\n",
    "                tof_attention_masks,\n",
    "                return_features=False):\n",
    "        # Process IMU\n",
    "        imu_feat = self.imu_branch(imu_seq, imu_len)\n",
    "\n",
    "        # Process THM\n",
    "        thm_feat = self.thm_branch(thm_seq, thm_len)\n",
    "\n",
    "        # Process ToF sensors\n",
    "        tof_feats = []\n",
    "        for i, branch in enumerate(self.tof_branches):\n",
    "            masked_tof = tof_inputs[i].clone()\n",
    "            masked_tof[~tof_attention_masks[i]] = 0\n",
    "            tof_feat = branch(masked_tof, tof_len)\n",
    "            tof_feats.append(tof_feat)\n",
    "\n",
    "        # Combine features\n",
    "        tokens = [imu_feat, thm_feat] + tof_feats\n",
    "        x = torch.stack(tokens, dim=1)\n",
    "\n",
    "        # Branch masking\n",
    "        attention_mask = None\n",
    "        if self.training and self.p_branch_mask > 0:\n",
    "            batch_mask = torch.bernoulli(\n",
    "                torch.full((len(tokens),), 1 - self.p_branch_mask, device=x.device)\n",
    "            )\n",
    "            attention_mask = (~batch_mask.bool()).expand(x.size(0), -1)\n",
    "\n",
    "        # Feature fusion\n",
    "        x = self.pre_norm(x)\n",
    "        x = self.feat_dropout(x)\n",
    "\n",
    "        for attn_layer in self.attention_layers:\n",
    "            attn_out, _ = attn_layer['attention'](\n",
    "                x, x, x,\n",
    "                key_padding_mask=attention_mask\n",
    "            )\n",
    "            x = x + attn_out\n",
    "            x = attn_layer['norm'](x)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            mask_expanded = (~attention_mask).float().unsqueeze(-1)\n",
    "            fused = (x * mask_expanded).sum(dim=1) / mask_expanded.sum(dim=1)\n",
    "        else:\n",
    "            fused = x.mean(dim=1)\n",
    "\n",
    "        out = self.ffn(fused)\n",
    "        out = self.post_norm(out)\n",
    "        logits = self.classifier(out)\n",
    "\n",
    "        if return_features:\n",
    "            return logits, out\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677f568d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T04:39:28.339743Z",
     "iopub.status.busy": "2025-07-11T04:39:28.339446Z",
     "iopub.status.idle": "2025-07-11T04:39:36.272374Z",
     "shell.execute_reply": "2025-07-11T04:39:36.271359Z"
    },
    "papermill": {
     "duration": 7.938502,
     "end_time": "2025-07-11T04:39:36.273915",
     "exception": false,
     "start_time": "2025-07-11T04:39:28.335413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 3 models\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model ensemble\n",
    "model_ensemble1 = []\n",
    "for i in range(1, 4):\n",
    "    # Create model instance\n",
    "    model = MultiSensorClassifier().to(device)\n",
    "    \n",
    "    # Load weights\n",
    "    if i==1:\n",
    "        model_path = '/kaggle/input/trained-model/best_model_fold1-9.pth'\n",
    "    else:\n",
    "        model_path = f\"/kaggle/input/trained-model/best_model_fold{i}.pth\"\n",
    "\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    model_ensemble1.append(model)\n",
    "\n",
    "print(f\"✅ Successfully loaded {len(model_ensemble1)} models\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6d9f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T22:29:18.956193Z",
     "iopub.status.busy": "2025-05-29T22:29:18.955791Z",
     "iopub.status.idle": "2025-05-29T22:29:18.965179Z",
     "shell.execute_reply": "2025-05-29T22:29:18.963797Z",
     "shell.execute_reply.started": "2025-05-29T22:29:18.956169Z"
    },
    "papermill": {
     "duration": 0.003037,
     "end_time": "2025-07-11T04:39:36.280578",
     "exception": false,
     "start_time": "2025-07-11T04:39:36.277541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The evaluation API requires that you set up a server which will respond to inference requests. We have already defined the server; you just need write the predict function. When we evaluate your submission on the hidden test set the client defined in the gateway will run in a different container with direct access to the hidden test set and hand off the one sequence at a time.\n",
    "\n",
    "Your code will always have access to the published copies of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa86e099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T04:39:36.288576Z",
     "iopub.status.busy": "2025-07-11T04:39:36.288259Z",
     "iopub.status.idle": "2025-07-11T04:39:36.314619Z",
     "shell.execute_reply": "2025-07-11T04:39:36.313740Z"
    },
    "papermill": {
     "duration": 0.032139,
     "end_time": "2025-07-11T04:39:36.315924",
     "exception": false,
     "start_time": "2025-07-11T04:39:36.283785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    # Convert to pandas and sort\n",
    "    df_seq = sequence.to_pandas().sort_values('sequence_counter')\n",
    "    \n",
    "    # Global references\n",
    "    global model_ensemble, model_ensemble1, idx_to_gesture, imu_cols\n",
    "    \n",
    "    # --- Check sensor availability first ---\n",
    "    # THM availability (check if any THM sensor has valid data)\n",
    "    thm_available = False\n",
    "    thm_cols = [f'thm_{i}' for i in range(1, 6)]\n",
    "    if all(col in df_seq.columns for col in thm_cols):\n",
    "        thm_data = df_seq[thm_cols].values.astype(np.float32)\n",
    "        if not np.all(np.isnan(thm_data)):\n",
    "            thm_available = True\n",
    "    \n",
    "    # ToF availability (check if any ToF sensor has valid data)\n",
    "    tof_available = False\n",
    "    for i in range(1, 6):\n",
    "        tof_cols = [f'tof_{i}_v{j}' for j in range(64)]\n",
    "        if all(col in df_seq.columns for col in tof_cols):\n",
    "            tof_vals = df_seq[tof_cols].values.astype(np.float32)\n",
    "            if not np.all(np.isnan(tof_vals)):\n",
    "                tof_available = True\n",
    "                break\n",
    "    \n",
    "    # Determine which model will be used\n",
    "    use_full_model = thm_available and tof_available  # Set to (thm_available and tof_available) when ready\n",
    "    \n",
    "    # --- Feature Engineering ---\n",
    "    # Replace NaN values with 0 in rotation columns\n",
    "    rotation_cols = ['rot_x', 'rot_y', 'rot_z', 'rot_w']\n",
    "    for col in rotation_cols:\n",
    "        if col in df_seq.columns:\n",
    "            df_seq[col] = df_seq[col].fillna(0)\n",
    "    \n",
    "    # Base features (needed by both models)\n",
    "    df_seq['acc_mag'] = np.sqrt(df_seq['acc_x']**2 + df_seq['acc_y']**2 + df_seq['acc_z']**2).astype(np.float32)\n",
    "    df_seq['rot_angle'] = (2 * np.arccos(df_seq['rot_w'].clip(-1, 1))).astype(np.float32)\n",
    "    \n",
    "    # Derivatives (needed by both models)\n",
    "    df_seq['acc_mag_jerk'] = df_seq['acc_mag'].diff().fillna(0).astype(np.float32)\n",
    "    df_seq['rot_angle_vel'] = df_seq['rot_angle'].diff().fillna(0).astype(np.float32)\n",
    "    \n",
    "    # Gravity removal (needed by both models)\n",
    "    acc_data = df_seq[['acc_x', 'acc_y', 'acc_z']]\n",
    "    rot_data = df_seq[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    linear_accel = remove_gravity_from_acc(acc_data, rot_data)\n",
    "    df_seq[['linear_acc_x', 'linear_acc_y', 'linear_acc_z']] = linear_accel\n",
    "    \n",
    "    # Linear acceleration features (needed by both models)\n",
    "    df_seq['linear_acc_mag'] = np.sqrt(df_seq['linear_acc_x']**2 + \n",
    "                                       df_seq['linear_acc_y']**2 + \n",
    "                                       df_seq['linear_acc_z']**2).astype(np.float32)\n",
    "    df_seq['linear_acc_mag_jerk'] = df_seq['linear_acc_mag'].diff().fillna(0).astype(np.float32)\n",
    "    \n",
    "    # Angular velocity (needed by both models)\n",
    "    angular_vel = calculate_angular_velocity_from_quat(rot_data)\n",
    "    df_seq[['angular_vel_x', 'angular_vel_y', 'angular_vel_z']] = angular_vel\n",
    "    \n",
    "    # Angular distance (needed by both models)\n",
    "    angular_dist = calculate_angular_distance(rot_data)\n",
    "    df_seq['angular_distance'] = angular_dist.astype(np.float32)\n",
    "    \n",
    "    # --- Additional features only for IMU-only model ---\n",
    "    if not use_full_model:\n",
    "        # Second derivatives (jerk of jerk)\n",
    "        df_seq['acc_x_jerk'] = df_seq['acc_x'].diff().fillna(0).astype(np.float32)\n",
    "        df_seq['acc_y_jerk'] = df_seq['acc_y'].diff().fillna(0).astype(np.float32)\n",
    "        df_seq['acc_z_jerk'] = df_seq['acc_z'].diff().fillna(0).astype(np.float32)\n",
    "        df_seq['acc_x_jerk_jerk'] = df_seq['acc_x_jerk'].diff().fillna(0).astype(np.float32)\n",
    "        df_seq['acc_y_jerk_jerk'] = df_seq['acc_y_jerk'].diff().fillna(0).astype(np.float32)\n",
    "        df_seq['acc_z_jerk_jerk'] = df_seq['acc_z_jerk'].diff().fillna(0).astype(np.float32)\n",
    "        \n",
    "        # Angular velocity magnitude and jerk\n",
    "        df_seq['angular_vel_mag'] = np.sqrt(df_seq['angular_vel_x']**2 + \n",
    "                                           df_seq['angular_vel_y']**2 + \n",
    "                                           df_seq['angular_vel_z']**2).astype(np.float32)\n",
    "        df_seq['angular_vel_mag_jerk'] = df_seq['angular_vel_mag'].diff().fillna(0).astype(np.float32)\n",
    "    \n",
    "    # Ensure all numeric columns are float32\n",
    "    for col in df_seq.select_dtypes(include=[np.number]).columns:\n",
    "        df_seq[col] = df_seq[col].astype(np.float32)\n",
    "    \n",
    "    # Define IMU columns for FULL model (fewer features)\n",
    "    # Full model uses: 7 base + 13 engineered = 20 features\n",
    "    initial_imu_cols = ['acc_x', 'acc_y', 'acc_z', 'rot_x', 'rot_y', 'rot_z', 'rot_w']\n",
    "    imu_cols_full = initial_imu_cols + [\n",
    "        # Basic engineered features\n",
    "        'acc_mag', 'rot_angle', 'acc_mag_jerk', 'rot_angle_vel',\n",
    "        # Linear acceleration\n",
    "        'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk',\n",
    "        # Angular features (only basic ones)\n",
    "        'angular_vel_x', 'angular_vel_y', 'angular_vel_z',\n",
    "        'angular_distance'\n",
    "    ]\n",
    "    \n",
    "    # Define IMU columns for IMU-ONLY model\n",
    "    # IMU-only model uses: 7 base + 21 engineered = 28 features\n",
    "    imu_cols_imu_only = initial_imu_cols + [\n",
    "        # Basic engineered features (4)\n",
    "        'acc_mag', 'rot_angle', 'acc_mag_jerk', 'rot_angle_vel',\n",
    "        # Jerk features (6)\n",
    "        'acc_x_jerk', 'acc_y_jerk', 'acc_z_jerk',\n",
    "        'acc_x_jerk_jerk', 'acc_y_jerk_jerk', 'acc_z_jerk_jerk',\n",
    "        # Linear acceleration (5)\n",
    "        'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk',\n",
    "        # Angular features (6)\n",
    "        'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_vel_mag', 'angular_vel_mag_jerk',\n",
    "        'angular_distance'\n",
    "    ]\n",
    "    \n",
    "    # Select which feature set to use based on model\n",
    "    if use_full_model:\n",
    "        imu_cols = imu_cols_full\n",
    "    else:\n",
    "        imu_cols = imu_cols_imu_only\n",
    "    \n",
    "    # --- Prepare IMU features ---\n",
    "    # Ensure all IMU columns exist\n",
    "    for col in imu_cols:\n",
    "        if col not in df_seq:\n",
    "            df_seq[col] = 0.0\n",
    "            \n",
    "    X = df_seq[imu_cols].values.astype(np.float32)\n",
    "    X = np.nan_to_num(X, nan=0.0)\n",
    "    T = X.shape[0]\n",
    "    \n",
    "    # --- Prepare tensors ---\n",
    "    device = next(model_ensemble[0].parameters()).device\n",
    "    \n",
    "    # IMU tensor (used by both models)\n",
    "    imu_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(0).to(device)  # (1, T, C)\n",
    "    imu_len = torch.tensor([T]).to(device)\n",
    "    \n",
    "    # --- Model Selection & Inference ---\n",
    "    if use_full_model:\n",
    "        # --- Full model with all sensors ---\n",
    "        # Prepare IMU data with only features used by full model\n",
    "        X_full = df_seq[imu_cols_full].values.astype(np.float32)\n",
    "        X_full = np.nan_to_num(X_full, nan=0.0)\n",
    "        imu_tensor_full = torch.tensor(X_full, dtype=torch.float32).unsqueeze(0).to(device)  # (1, T, C)\n",
    "        \n",
    "        # Prepare THM data\n",
    "        thm_data = np.zeros((T, 5), dtype=np.float32)\n",
    "        for i, col in enumerate(thm_cols):\n",
    "            if col in df_seq:\n",
    "                thm_data[:, i] = df_seq[col].fillna(0).values\n",
    "        \n",
    "        # Prepare ToF data and masks\n",
    "        tof_inputs = []\n",
    "        tof_masks = []\n",
    "        \n",
    "        for i in range(1, 6):\n",
    "            tof_cols = [f'tof_{i}_v{j}' for j in range(64)]\n",
    "            arr = np.zeros((T, 64), dtype=np.float32)\n",
    "            mask = np.zeros(T, dtype=bool)\n",
    "            \n",
    "            if all(col in df_seq.columns for col in tof_cols):\n",
    "                tof_vals = df_seq[tof_cols].values.astype(np.float32)\n",
    "                valid_mask = ~(np.isnan(tof_vals).all(axis=1) | (tof_vals == -1).all(axis=1))\n",
    "                \n",
    "                if np.any(valid_mask):\n",
    "                    arr = tof_vals.copy()\n",
    "                    arr[arr == -1] = 512  # Using 512 as your replacement value\n",
    "                    arr = np.nan_to_num(arr, nan=1000)\n",
    "                    mask = valid_mask\n",
    "            \n",
    "            tof_inputs.append(arr)\n",
    "            tof_masks.append(mask)\n",
    "        \n",
    "        # Create tensors\n",
    "        thm_tensor = torch.tensor(thm_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        thm_len = torch.tensor([T]).to(device)\n",
    "        tof_tensors = [torch.tensor(arr, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                       for arr in tof_inputs]\n",
    "        tof_mask_tensors = [torch.tensor(mask, dtype=torch.bool).unsqueeze(0).to(device)\n",
    "                            for mask in tof_masks]\n",
    "        tof_len = torch.tensor([T]).to(device)\n",
    "        \n",
    "        # Run full model ensemble inference\n",
    "        all_logits = []\n",
    "        for model in model_ensemble1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                logits = model(\n",
    "                    imu_tensor_full, imu_len,\n",
    "                    thm_tensor, thm_len,\n",
    "                    tof_tensors, tof_len,\n",
    "                    tof_mask_tensors\n",
    "                )\n",
    "                all_logits.append(logits)\n",
    "    else:\n",
    "        # --- IMU-only model ---\n",
    "        all_logits = []\n",
    "        for model in model_ensemble:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # New model expects (B, T, C) and handles transpose internally\n",
    "                logits = model(imu_tensor, imu_len)   # shape (1, n_classes)\n",
    "                all_logits.append(logits)\n",
    "\n",
    "    # --- Ensemble Weighted Averaging ---\n",
    "    stacked = torch.stack(all_logits)      # shape: (num_models, batch, n_classes)\n",
    "    num_models = stacked.size(0)\n",
    "    \n",
    "    if num_models == 10:\n",
    "        w = torch.tensor([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], device=device)\n",
    "    else:\n",
    "        w = torch.tensor([0.33, 0.33, 0.33], device=device)  # pick whatever you like\n",
    "    \n",
    "    w = w.view(num_models, 1, 1)            # (num_models, 1, 1)\n",
    "    avg_logits = (stacked * w).sum(dim=0)   # weighted sum → (batch, n_classes)\n",
    "    pred_idx = avg_logits.argmax(1).item()\n",
    "    \n",
    "    # Timing and output\n",
    "    print(f\"Prediction: {idx_to_gesture[pred_idx]}\")\n",
    "    \n",
    "    return idx_to_gesture[pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1904238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T04:39:36.323829Z",
     "iopub.status.busy": "2025-07-11T04:39:36.323561Z",
     "iopub.status.idle": "2025-07-11T04:39:39.865552Z",
     "shell.execute_reply": "2025-07-11T04:39:39.864680Z"
    },
    "papermill": {
     "duration": 3.547515,
     "end_time": "2025-07-11T04:39:39.866890",
     "exception": false,
     "start_time": "2025-07-11T04:39:36.319375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Neck - scratch\n",
      "Prediction: Eyelash - pull hair\n"
     ]
    }
   ],
   "source": [
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdbbea",
   "metadata": {
    "papermill": {
     "duration": 0.003141,
     "end_time": "2025-07-11T04:39:39.873751",
     "exception": false,
     "start_time": "2025-07-11T04:39:39.870610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7700311,
     "sourceId": 12436533,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 68.560195,
   "end_time": "2025-07-11T04:39:42.566190",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-11T04:38:34.005995",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
